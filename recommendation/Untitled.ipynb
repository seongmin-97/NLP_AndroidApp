{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx\n",
    "import re\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#출처 : https://bab2min.tistory.com/570\n",
    "class RawTaggerReader:\n",
    "    def __init__(self, plot, tagger = None):\n",
    "        if tagger:\n",
    "            self.tagger = tagger\n",
    "        else :\n",
    "            from konlpy.tag import Komoran\n",
    "            self.tagger = Komoran()\n",
    "        self.plot = plot\n",
    "        self.rgxSplitter = re.compile('([.!?:](?:[\"\\']|(?![0-9])))')\n",
    " \n",
    "    def __iter__(self):\n",
    "        ch = self.rgxSplitter.split(self.plot)\n",
    "        if len(ch) == 1: ch.append('.')\n",
    "        for s in map(lambda a,b:a+b, ch[::2], ch[1::2]):\n",
    "            if not s: continue\n",
    "            yield self.tagger.pos(s)\n",
    "\n",
    "class TextRank:\n",
    "    def __init__(self, **kargs):\n",
    "        self.graph = None\n",
    "        self.window = kargs.get('window', 5)\n",
    "        self.coef = kargs.get('coef', 1.0)\n",
    "        self.threshold = kargs.get('threshold', 0.005)\n",
    "        self.dictCount = {}\n",
    "        self.dictBiCount = {}\n",
    "        self.dictNear = {}\n",
    "        self.nTotal = 0\n",
    "\n",
    "    def load(self, sentenceIter, wordFilter = None):\n",
    "        def insertPair(a, b):\n",
    "            if a > b: a, b = b, a\n",
    "            elif a == b: return\n",
    "            self.dictBiCount[a, b] = self.dictBiCount.get((a, b), 0) + 1\n",
    " \n",
    "        def insertNearPair(a, b):\n",
    "            self.dictNear[a, b] = self.dictNear.get((a, b), 0) + 1\n",
    " \n",
    "        for sent in sentenceIter:\n",
    "            for i, word in enumerate(sent):\n",
    "                if wordFilter and not wordFilter(word): continue\n",
    "                self.dictCount[word] = self.dictCount.get(word, 0) + 1\n",
    "                self.nTotal += 1\n",
    "                if i - 1 >= 0 and (not wordFilter or wordFilter(sent[i-1])): insertNearPair(sent[i-1], word)\n",
    "                if i + 1 < len(sent) and (not wordFilter or wordFilter(sent[i+1])): insertNearPair(word, sent[i+1])\n",
    "                for j in range(i+1, min(i+self.window+1, len(sent))):\n",
    "                    if wordFilter and not wordFilter(sent[j]): continue\n",
    "                    if sent[j] != word: insertPair(word, sent[j])\n",
    "\n",
    "    def getPMI(self, a, b):\n",
    "        import math\n",
    "        co = self.dictNear.get((a, b), 0)\n",
    "        if not co: return None\n",
    "        return math.log(float(co) * self.nTotal / self.dictCount[a] / self.dictCount[b])\n",
    " \n",
    "    def getI(self, a):\n",
    "        import math\n",
    "        if a not in self.dictCount: return None\n",
    "        return math.log(self.nTotal / self.dictCount[a])\n",
    " \n",
    "    def build(self):\n",
    "        self.graph = networkx.Graph()\n",
    "        self.graph.add_nodes_from(self.dictCount.keys())\n",
    "        for (a, b), n in self.dictBiCount.items():\n",
    "            self.graph.add_edge(a, b, weight=n*self.coef + (1-self.coef))\n",
    " \n",
    "    def rank(self):\n",
    "        return networkx.pagerank(self.graph, weight='weight')\n",
    " \n",
    "    def extract(self, ratio = 0.1):\n",
    "        ranks = self.rank()\n",
    "\n",
    "        if int(len(ranks) * ratio) > 10:\n",
    "            cand = sorted(ranks, key=ranks.get, reverse=True)[:int(len(ranks) * ratio)]\n",
    "        else:\n",
    "            cand = sorted(ranks, key=ranks.get, reverse=True)[:10]\n",
    "        pairness = {}\n",
    "        startOf = {}\n",
    "        tuples = {}\n",
    "\n",
    "        for k in cand:\n",
    "            tuples[(k,)] = self.getI(k) * ranks[k]\n",
    "            for l in cand:\n",
    "                if k == l: continue\n",
    "                pmi = self.getPMI(k, l)\n",
    "                if pmi: pairness[k, l] = pmi\n",
    " \n",
    "        for (k, l) in sorted(pairness, key=pairness.get, reverse=True):\n",
    "            if k not in startOf: startOf[k] = (k, l)\n",
    " \n",
    "        for (k, l), v in pairness.items():\n",
    "            pmis = v\n",
    "            rs = ranks[k] * ranks[l]\n",
    "            path = (k, l)\n",
    "            tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "            last = l\n",
    "            while last in startOf and len(path) < 7:\n",
    "                if last in path: break\n",
    "                pmis += pairness[startOf[last]]\n",
    "                last = startOf[last][1]\n",
    "                rs *= ranks[last]\n",
    "                path += (last,)\n",
    "                tuples[path] = pmis / (len(path) - 1) * rs ** (1 / len(path)) * len(path)\n",
    "\n",
    "        used = set()\n",
    "        both = {}\n",
    "        for k in sorted(tuples, key=tuples.get, reverse=True):\n",
    "            if len(k) == 1:\n",
    "                if used.intersection(set(k)): continue\n",
    "                both[k] = tuples[k]\n",
    "                for w in k:\n",
    "                    used.add(w)\n",
    "        \n",
    "        return both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/naver_movie_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 /10255 ['의', 'ㄴ', '아', '을', '이', '하', '를', '는', '가문', '어', '프레디', '늑대인간', '에', '는', '!']\n",
      "100 /10255 ['을', '하', '는', 'ㄴ', '고', '의', '가', '에', '를', '는', '하', '박사', '세계', '나치', '로저', '대위', '에리스', '있', '.', '부대', '로', '부대원', '에서']\n",
      "200 /10255 [',', 'ㄴ', '를', '는', '은', '도', '.', '며', '하', '에서', '하루', '지', '날', '의', '어느', '꿈', '이', '카페', 'ㄴ다']\n",
      "300 /10255 ['ㄴ', '들', '하', '되', '을', '이', '에', '섬', ',', '은', '가', '기', '고', '하']\n",
      "400 /10255 ['’', '‘', 'ㄴ', '하', '과', '은', '의', '석영', '에게', '남', '여자', '중', '들', '를', '자리', '는', '.']\n",
      "500 /10255 ['을', '하', '아', '은', '만', '경', ')', '는', '를', 'ㄴ', '(', '은', '게', '에', '며', '도', '행사', '의', '팔순', '기', '.']\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for idx in df.index:\n",
    "    keywords = []\n",
    "    tr = TextRank(window=5, coef=1)\n",
    "    tr.load(RawTaggerReader(df.loc[idx,'plot']))\n",
    "            #and w[0] in model_kmr.wv.vocab and (w[1] in ('NNG', 'NNP', 'VV')))\n",
    "    tr.build()\n",
    "    kw = tr.extract(0.2)\n",
    "    for k in sorted(kw, key=kw.get, reverse=True):\n",
    "        keywords.append(k[0][0])\n",
    "        #print(\"%s\\t%g\" % (k, kw[k]))\n",
    "    if idx %100 == 0:\n",
    "        print(idx,'/10255',keywords)\n",
    "    results.append(keywords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
