{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = '../Embedding/embedding_data/'\n",
    "model = FastText.load(DATA_IN_PATH + 'FastText_embedding.model').wv\n",
    "# FastText 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../data/naverReview_label.csv')\n",
    "train_data = pd.read_csv('../data/preprocess/naverReview_preprocess_Okt.csv', encoding = 'UTF8')\n",
    "#필요한 라벨, 트레인 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([train_data, label_data], axis=1)\n",
    "#nan제거를 위해 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>아 더빙 진짜 짜증나다 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>너 무재 밓었 다그 래서 보다 추천 한 다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>교도소 이야기 구먼 솔직하다 재미 는 없다 평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 스파이더맨 에서 늙다 보이다 하...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199987</th>\n",
       "      <td>오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199988</th>\n",
       "      <td>의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199989</th>\n",
       "      <td>그림 도 좋다 완성 도도 높다 보다 내내 불안하다 만들다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199990</th>\n",
       "      <td>절대 보다 서다 안 되다 영화 재미 도 없다 기분 만 잡 치고 하다 세트 장 에서 ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199991</th>\n",
       "      <td>마무리 는 또 왜 이래</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>199992 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context  label\n",
       "0                                        아 더빙 진짜 짜증나다 목소리      0\n",
       "1                        흠 포스터 보고 초딩 영화 줄 오버 연기 조차 가볍다 않다      1\n",
       "2                                 너 무재 밓었 다그 래서 보다 추천 한 다      0\n",
       "3                           교도소 이야기 구먼 솔직하다 재미 는 없다 평점 조정      0\n",
       "4       사이 몬페 그 의 익살스럽다 연기 가 돋보이다 영화 스파이더맨 에서 늙다 보이다 하...      1\n",
       "...                                                   ...    ...\n",
       "199987   오랜 만 에 평점 로 기다 하다 ㅋㅋ 킹왕짱 쌈뽕 한 영화 를 만나다 강렬하다 육 쾌함      1\n",
       "199988         의지 박약 들 이나 하다 탈영 은 일단 주인공 김대희 닮다 이등병 찌다 따다      0\n",
       "199989                    그림 도 좋다 완성 도도 높다 보다 내내 불안하다 만들다      0\n",
       "199990  절대 보다 서다 안 되다 영화 재미 도 없다 기분 만 잡 치고 하다 세트 장 에서 ...      0\n",
       "199991                                       마무리 는 또 왜 이래      0\n",
       "\n",
       "[199992 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2 = new_data.dropna()\n",
    "#nan 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(new_data2['label'])\n",
    "contexts = list(new_data2['context'])\n",
    "#라벨 리뷰 분리\n",
    "sentences = []\n",
    "for context in contexts :\n",
    "    sentences.append(str(context).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(words, model, num_features) :\n",
    "    feature_vector = np.zeros((num_features), dtype = np.float32)\n",
    "    \n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words :\n",
    "        if w in index2word_set :\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features) :\n",
    "    dataset = list()\n",
    "    \n",
    "    for s in reviews :\n",
    "        dataset.append(get_feature(s, model, num_features))\n",
    "        \n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-8-c82fc869ee2a>:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  index2word_set = set(model.wv.index2word)\n",
      "<ipython-input-8-c82fc869ee2a>:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vector = np.divide(feature_vector, num_words)\n"
     ]
    }
   ],
   "source": [
    "num_features = 100\n",
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_vecs.tolist()\n",
    "test_data_df = pd.DataFrame({'context' : test_data})\n",
    "label_df = pd.DataFrame({'label': labels})\n",
    "#nan 제거를 위해 각각 df 화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([test_data_df, label_df], axis=1)\n",
    "#nan 제거를 위해 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 79, 151, 169, 414, 1150, 1349, 1575, 1715, 2328, 2352, 2440, 3220, 3451, 4307, 4830, 5043, 5748, 5827, 7078, 7187, 7839, 8395, 9407, 9726, 9964, 10678, 10714, 11061, 11764, 12609, 12829, 12875, 13011, 13545, 13646, 13788, 13915, 15579, 15591, 15838, 16952, 18795, 18824, 19493, 20631, 20761, 21531, 21569, 22354, 23298, 24865, 25154, 25315, 26152, 26610, 27432, 27830, 28819, 28946, 29290, 29991, 30575, 31020, 31330, 32639, 33140, 33310, 33322, 34482, 34686, 34838, 35400, 36802, 37622, 38009, 40223, 40593, 40957, 41267, 41591, 43869, 43976, 44074, 44510, 44657, 44768, 45315, 45495, 46047, 46089, 46840, 47074, 47514, 47636, 48189, 48605, 49583, 49615, 49736, 50449, 50785, 51902, 52766, 52871, 53624, 53829, 54425, 54956, 55527, 55768, 55791, 56424, 57024, 57196, 57906, 57975, 58342, 59817, 61460, 61744, 62836, 63006, 63169, 63668, 64173, 64581, 64733, 65351, 65453, 66323, 66634, 67114, 67217, 67848, 68139, 68623, 68902, 69137, 69261, 70715, 70967, 71386, 71767, 72591, 73423, 73434, 74589, 75081, 75166, 75362, 75542, 76910, 77324, 78809, 78856, 79189, 79482, 79881, 80651, 80880, 81253, 81485, 82068, 82181, 83389, 84432, 84448, 86131, 86156, 86614, 88291, 88347, 88972, 89080, 89192, 89780, 90435, 90763, 91041, 91416, 92355, 92628, 92942, 92944, 94658, 94907, 95407, 95565, 95728, 96194, 97022, 97988, 98491, 99152, 99437, 100935, 101690, 101913, 102798, 103336, 104722, 104855, 105368, 105486, 105681, 106364, 107226, 108521, 108554, 109135, 109148, 109266, 109284, 110464, 110584, 110882, 112259, 114954, 115244, 115290, 115359, 116192, 116546, 116562, 117128, 118396, 118758, 118886, 119451, 119532, 120191, 120368, 120486, 120501, 120571, 120659, 120813, 120904, 121116, 121913, 122436, 123149, 123520, 123747, 124553, 124714, 124756, 124782, 125582, 125635, 126264, 126309, 126342, 126447, 128097, 128427, 128822, 129183, 130838, 131449, 131974, 132316, 132392, 132399, 132588, 133206, 133435, 133979, 134159, 134539, 134703, 135527, 135697, 136118, 136126, 136345, 136495, 136766, 136905, 136992, 137311, 137952, 138611, 139123, 139678, 139719, 139783, 140164, 141379, 141535, 142197, 143293, 143713, 143913, 145799, 145874, 146514, 148190, 148303, 148912, 149585, 150953, 150982, 151026, 151119, 151152, 151182, 151331, 152566, 152676, 152951, 153713, 153829, 154443, 155444, 155634, 156230, 156315, 157002, 157118, 157186, 157348, 157763, 157785, 159321, 159807, 160191, 161456, 161830, 161884, 162741, 163123, 163351, 163588, 164235, 164271, 164606, 164751, 164764, 166382, 166519, 166624, 168196, 168317, 168425, 169985, 170060, 170274, 170636, 170897, 172008, 172195, 172236, 172936, 173129, 173311, 173316, 174813, 175003, 175839, 176616, 177422, 177423, 178106, 178187, 178780, 179083, 179369, 179391, 179489, 179719, 179868, 180101, 180261, 180403, 181379, 181500, 182565, 182764, 182992, 183237, 183609, 184356, 184496, 184565, 184651, 184705, 185141, 185600, 186149, 186250, 187141, 187803, 187972, 188495, 188597, 188683, 188787, 189274, 190892, 191029, 191215, 191482, 191489, 191542, 192486, 192721, 193235, 193283, 193514, 193619, 194272, 194625, 194654, 194789, 195249, 195394, 196150, 196430, 196640, 196827, 198269]\n"
     ]
    }
   ],
   "source": [
    "nan_index = []\n",
    "for index in range(198315) :\n",
    "    npArray = np.asarray(new_df['context'].iloc[index], dtype=np.float32)\n",
    "    if np.isnan(npArray).any() :\n",
    "        nan_index.append(index)\n",
    "        \n",
    "print(nan_index)\n",
    "#nan 찾는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.1258326768875122, -0.22390116751194, -0.31...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.1259692907333374, -0.08359721302986145, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[-0.0668153241276741, -0.03492670878767967, -0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.1706537902355194, 0.11785295605659485, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.035351455211639404, 0.03357141464948654, 0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198310</th>\n",
       "      <td>[-0.07117301225662231, 0.08433877676725388, -0...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198311</th>\n",
       "      <td>[-0.010580337606370449, 0.01028466410934925, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198312</th>\n",
       "      <td>[-0.06006656959652901, 0.0936768501996994, -0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198313</th>\n",
       "      <td>[-0.09329956769943237, -0.05762521177530289, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198314</th>\n",
       "      <td>[-0.17478375136852264, 0.16087009012699127, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197892 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context  label\n",
       "0       [-0.1258326768875122, -0.22390116751194, -0.31...      0\n",
       "1       [-0.1259692907333374, -0.08359721302986145, -0...      1\n",
       "2       [-0.0668153241276741, -0.03492670878767967, -0...      0\n",
       "3       [-0.1706537902355194, 0.11785295605659485, -0....      0\n",
       "4       [-0.035351455211639404, 0.03357141464948654, 0...      1\n",
       "...                                                   ...    ...\n",
       "198310  [-0.07117301225662231, 0.08433877676725388, -0...      1\n",
       "198311  [-0.010580337606370449, 0.01028466410934925, -...      0\n",
       "198312  [-0.06006656959652901, 0.0936768501996994, -0....      0\n",
       "198313  [-0.09329956769943237, -0.05762521177530289, -...      0\n",
       "198314  [-0.17478375136852264, 0.16087009012699127, 0....      0\n",
       "\n",
       "[197892 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df2 = new_df.drop(nan_index)\n",
    "new_df2\n",
    "#nan 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = list(new_df2['label'])\n",
    "contexts2 = list(new_df2['context'])\n",
    "#로지스틱에 필요한 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(contexts2)\n",
    "y = np.array(labels2)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lgs = LogisticRegression(class_weight='balanced')\n",
    "lgs.fit(X_train, y_train)\n",
    "#로지스틱 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 정확도 : 0.819863\n",
      "테스트 데이터 정확도 : 0.820107\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 정확도 : %f\" % lgs.score(X_train, y_train))\n",
    "print(\"테스트 데이터 정확도 : %f\" % lgs.score(X_test, y_test))\n",
    "#정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, okt, remove_stopwords = False):\n",
    "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
    "    word_review = okt.morphs(review_text, stem = True)\n",
    "    \n",
    "    word_review = ' '.join(word_review)\n",
    "    \n",
    "    return word_review\n",
    "#예측을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_predict(words, model, num_features) :\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for w in words.split() :\n",
    "        if w in index2word_set :\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review) :\n",
    "    global model, num_features\n",
    "    clean_review = preprocessing(review, okt, remove_stopwords=False)\n",
    "    result = get_feature_predict(clean_review, model, num_features)\n",
    "    List = []\n",
    "    List.append(result)\n",
    "    return lgs.predict(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-f1669c899350>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  index2word_set = set(model.wv.index2word)\n",
      "<ipython-input-21-f1669c899350>:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  feature_vector = np.add(feature_vector, model.wv[w])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"영화너무 재밌었다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
