{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN_PATH = '../Embedding/embedding_data/'\n",
    "model = Word2Vec.load(DATA_IN_PATH + 'Word2Vec_embedding.model').wv\n",
    "# Word2Vec 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_data = pd.read_csv('../data/naverReview_label.csv')\n",
    "train_data = pd.read_csv('../data/preprocess/naverReview_preprocess_Okt.csv', encoding = 'UTF8')\n",
    "#필요한 라벨, 트레인 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.concat([train_data, label_data], axis=1)\n",
    "#nan제거를 위해 합치기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data2 = new_data.dropna()\n",
    "#nan 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(new_data2['label'])\n",
    "contexts = list(new_data2['context'])\n",
    "#라벨 리뷰 분리\n",
    "sentences = []\n",
    "for context in contexts :\n",
    "    sentences.append(str(context).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(words, model, num_features) :\n",
    "    feature_vector = np.zeros((num_features), dtype = np.float32)\n",
    "    \n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    \n",
    "    for w in words :\n",
    "        if w in index2word_set :\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(reviews, model, num_features) :\n",
    "    dataset = list()\n",
    "    \n",
    "    for s in reviews :\n",
    "        dataset.append(get_feature(s, model, num_features))\n",
    "        \n",
    "    reviewFeatureVecs = np.stack(dataset)\n",
    "    \n",
    "    return reviewFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-c82fc869ee2a>:5: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  index2word_set = set(model.wv.index2word)\n",
      "<ipython-input-7-c82fc869ee2a>:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  feature_vector = np.divide(feature_vector, num_words)\n"
     ]
    }
   ],
   "source": [
    "num_features = 100\n",
    "test_data_vecs = get_dataset(sentences, model, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data_vecs.tolist()\n",
    "test_data_df = pd.DataFrame({'context' : test_data})\n",
    "label_df = pd.DataFrame({'label': labels})\n",
    "#nan 제거를 위해 각각 df 화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([test_data_df, label_df], axis=1)\n",
    "#nan 제거를 위해 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28, 79, 169, 414, 1150, 1349, 1575, 1715, 2328, 2352, 2440, 3451, 4307, 4830, 5043, 5748, 7187, 7839, 8395, 9407, 9726, 10678, 11061, 11764, 12829, 12875, 13011, 13646, 13788, 15579, 15838, 16952, 18795, 18824, 19493, 20631, 21531, 23298, 24865, 25154, 25315, 26152, 26610, 27432, 27830, 28819, 28946, 29290, 29991, 30575, 31020, 31330, 32639, 33140, 33310, 33322, 34482, 34686, 35400, 36802, 37622, 38009, 40223, 40593, 40957, 41267, 43869, 44074, 44510, 44768, 45315, 45495, 46047, 46089, 46840, 47074, 47514, 47636, 48189, 48605, 49583, 49615, 49736, 50449, 50785, 51902, 52871, 53624, 53829, 54425, 54956, 55527, 55768, 56424, 57196, 57906, 57975, 58342, 59817, 61460, 61744, 62836, 63006, 63169, 63668, 64173, 64581, 64733, 65351, 65453, 66323, 66634, 67217, 67848, 68139, 68902, 69137, 69261, 70715, 71386, 71767, 72591, 73434, 74589, 75081, 75166, 75362, 75542, 76910, 77324, 78809, 78856, 79189, 79482, 79881, 80651, 81253, 81485, 82068, 82181, 83389, 84432, 86131, 86614, 88291, 88347, 88972, 89080, 89192, 89780, 90435, 90763, 91041, 91416, 92355, 92628, 92944, 94658, 94907, 95407, 95565, 95728, 96194, 97022, 97988, 98491, 99152, 100935, 101690, 101913, 103336, 104722, 105368, 105486, 105681, 106364, 107226, 108554, 109135, 109148, 109266, 110464, 110584, 112259, 114954, 115244, 115290, 115359, 116192, 116546, 116562, 117128, 118396, 118758, 118886, 119451, 119532, 120368, 120486, 120501, 120571, 120659, 120813, 120904, 121116, 121913, 122436, 123149, 123747, 124553, 124714, 124756, 124782, 125582, 125635, 126309, 126342, 126447, 128097, 128427, 128822, 129183, 130838, 131449, 131974, 132316, 132399, 132588, 133206, 133435, 133979, 134159, 134539, 134703, 135527, 135697, 136118, 136126, 136345, 136495, 136766, 136905, 136992, 137311, 137952, 138611, 139123, 139719, 139783, 140164, 141379, 143293, 143713, 143913, 145799, 145874, 148190, 148303, 148912, 150982, 151026, 151119, 151331, 152566, 152951, 153713, 154443, 155444, 155634, 157002, 157186, 157348, 157763, 157785, 159321, 159807, 160191, 161456, 161830, 161884, 162741, 163123, 163351, 163588, 164235, 164271, 164606, 164751, 166382, 166519, 166624, 168196, 168425, 169985, 170060, 170274, 170636, 170897, 172008, 172195, 172236, 172936, 173129, 173311, 173316, 174813, 175839, 176616, 177422, 177423, 178106, 178187, 178780, 179083, 179369, 179391, 179489, 179719, 179868, 180101, 180261, 180403, 181500, 182565, 182764, 182992, 183237, 183609, 184356, 184496, 184565, 184651, 184705, 185141, 185600, 186149, 186250, 187803, 187972, 188495, 188597, 188787, 189274, 191215, 191482, 191489, 191542, 192486, 192721, 193235, 193514, 193619, 194272, 194625, 194654, 195249, 195394, 196430, 196640, 196827, 198269]\n"
     ]
    }
   ],
   "source": [
    "nan_index = []\n",
    "for index in range(198315) :\n",
    "    npArray = np.asarray(new_df['context'].iloc[index], dtype=np.float32)\n",
    "    if np.isnan(npArray).any() :\n",
    "        nan_index.append(index)\n",
    "        \n",
    "print(nan_index)\n",
    "#nan 찾는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-0.3545059561729431, -0.04077335447072983, 0....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[-0.26670029759407043, 0.008713889867067337, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[0.04544483870267868, -0.005405960604548454, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[-0.24363183975219727, -0.09286148101091385, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[-0.07732874900102615, -0.03550983592867851, -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198310</th>\n",
       "      <td>[-0.0050431666895747185, -0.032580893486738205...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198311</th>\n",
       "      <td>[-0.16151383519172668, -0.004260162357240915, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198312</th>\n",
       "      <td>[-0.20260755717754364, -0.05997707322239876, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198313</th>\n",
       "      <td>[-0.10150811821222305, -0.03976898640394211, 0...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198314</th>\n",
       "      <td>[-0.14585307240486145, -0.07677726447582245, -...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>197954 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  context  label\n",
       "0       [-0.3545059561729431, -0.04077335447072983, 0....      0\n",
       "1       [-0.26670029759407043, 0.008713889867067337, -...      1\n",
       "2       [0.04544483870267868, -0.005405960604548454, 0...      0\n",
       "3       [-0.24363183975219727, -0.09286148101091385, 0...      0\n",
       "4       [-0.07732874900102615, -0.03550983592867851, -...      1\n",
       "...                                                   ...    ...\n",
       "198310  [-0.0050431666895747185, -0.032580893486738205...      1\n",
       "198311  [-0.16151383519172668, -0.004260162357240915, ...      0\n",
       "198312  [-0.20260755717754364, -0.05997707322239876, 0...      0\n",
       "198313  [-0.10150811821222305, -0.03976898640394211, 0...      0\n",
       "198314  [-0.14585307240486145, -0.07677726447582245, -...      0\n",
       "\n",
       "[197954 rows x 2 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df2 = new_df.drop(nan_index)\n",
    "new_df2\n",
    "#nan 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels2 = list(new_df2['label'])\n",
    "contexts2 = list(new_df2['context'])\n",
    "#랜덤포레스트에 필요한 데이터 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = np.array(contexts2)\n",
    "y = np.array(labels2)\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SPLIT, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest = RandomForestClassifier(n_estimators=100)\n",
    "forest.fit(X_train, y_train)\n",
    "#랜덤 포레스트 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터 정확도 : 0.995997\n",
      "테스트 데이터 정확도 : 0.821475\n"
     ]
    }
   ],
   "source": [
    "print(\"훈련 데이터 정확도 : %f\" % forest.score(X_train, y_train))\n",
    "print(\"테스트 데이터 정확도 : %f\" % forest.score(X_test, y_test))\n",
    "#정확도"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "okt=Okt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(review, okt, remove_stopwords = False):\n",
    "    review_text = re.sub(\"[^가-힣ㄱ-ㅎㅏ-ㅣ\\\\s]\", \"\", review)\n",
    "    word_review = okt.morphs(review_text, stem = True)\n",
    "    \n",
    "    word_review = ' '.join(word_review)\n",
    "    \n",
    "    return word_review\n",
    "#예측을 위한 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_predict(words, model, num_features) :\n",
    "    feature_vector = np.zeros((num_features), dtype=np.float32)\n",
    "    num_words = 0\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for w in words.split() :\n",
    "        if w in index2word_set :\n",
    "            num_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[w])\n",
    "    feature_vector = np.divide(feature_vector, num_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review) :\n",
    "    global model, num_features\n",
    "    clean_review = preprocessing(review, okt, remove_stopwords=False)\n",
    "    result = get_feature_predict(clean_review, model, num_features)\n",
    "    List = []\n",
    "    List.append(result)\n",
    "    return forest.predict(List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-f1669c899350>:4: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  index2word_set = set(model.wv.index2word)\n",
      "<ipython-input-22-f1669c899350>:8: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  feature_vector = np.add(feature_vector, model.wv[w])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(\"와 진짜 또 보고싶다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
